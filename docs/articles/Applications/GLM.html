<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Using Generalized Linear Models • embed</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="../../tidyverse.css" rel="stylesheet">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- tidyverse --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../jquery.sticky-kit.min.js"></script><script src="../../pkgdown.js"></script><!-- mathjax --><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <div class="navbar-brand-container">
        <a class="navbar-brand" href="../../index.html">embed</a>
        <small class="tidyverse">part of the <a href="https://tidyverse.org">tidyverse</a></small>
      </div>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right">
<li>
  <a href="../../articles/Applications/GLM.html">Generalized Linear Models</a>
</li>
<li>
  <a href="../../articles/Applications/Tensorflow.html">Tensorflow</a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
        
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Using Generalized Linear Models</h1>
            
      
      
      <div class="hidden name"><code>GLM.Rmd</code></div>

    </div>

    
    
<p>This method uses a generalized linear model to estimate the effect of each level of a factor predictor on the outcome. These values are retained to serve as the new encodings for the factor levels. This is sometimes referred to as <em>likelihood encodings</em>. <code>embed</code> has two estimation methods for accomplishing this: with and without pooling.</p>
<p>The example used here is the OkCupid data from <a href="http://www.amstat.org/publications/jse/v23n2/kim.pdf">Kim and Escobedo-Land (2015)(pdf)</a>. In <a href="http://feat.engineering">Kuhn and Johnson (2018)</a>, these data are used to predict whether a person is in the STEM fields (science, technology, engineering, and mathematics). One predictor, geographic location, is a factor variable. The frequencies of location in the data set used here vary between 1 person and 31064 per location. There are 135 locations in the data. Rather than producing 134 indicator variables for a model, a single numeric variable can be used to represent the <em>effect</em> or <em>impact</em> of the factor level on the outcome. In this case, where a factor outcome is being predicted (STEM or not), the effects are quantified by the log-odds of the location for being STEM.</p>
<p>We first calculate the raw log-odds for the data (independent of any model):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(embed)
<span class="kw">data</span>(okc)

props &lt;-<span class="st"> </span>okc <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(location) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(
    <span class="dt">prop =</span> <span class="kw">mean</span>(Class <span class="op">==</span><span class="st"> "stem"</span>),
    <span class="dt">log_odds  =</span> <span class="kw">log</span>(prop<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>prop)),
    <span class="dt">n =</span> <span class="kw">length</span>(Class)
  ) 
props</code></pre></div>
<pre><code>## # A tibble: 135 x 4
##    location            prop log_odds     n
##    &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;
##  1 alameda           0.143     -1.79   910
##  2 albany            0.163     -1.64   233
##  3 arcadia           0       -Inf        1
##  4 ashland           0       -Inf        1
##  5 atherton          0.222     -1.25    45
##  6 bayshore          0       -Inf        3
##  7 belmont           0.222     -1.25   243
##  8 belvedere tiburon 0.0702    -2.58    57
##  9 benicia           0.0837    -2.39   203
## 10 berkeley          0.140     -1.82  4212
## # ... with 125 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># later, for plotting</span>
rng &lt;-<span class="st"> </span><span class="kw">extendrange</span>(props<span class="op">$</span>log_odds[<span class="kw">is.finite</span>(props<span class="op">$</span>log_odds)], <span class="dt">f =</span> <span class="fl">0.1</span>)</code></pre></div>
<p>In subsequent sections, a logistic regression model is used. When the outcome variable is numeric, the steps automatically use linear regression models to estimate effects.</p>
<div id="no-pooling" class="section level2">
<h2 class="hasAnchor">
<a href="#no-pooling" class="anchor"></a>No Pooling</h2>
<p>In this case, the effect of each location can be estimated separately for each factor level. One method for conducting this estimation step is to fit a logistic regression with the STEM classification as the outcome and the location as the predictor. From this, the log-odds are naturally estimated by logistic regression.</p>
<p>For these data, a recipe is created and <code>step_lencode_glm</code> is used:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">okc_glm &lt;-<span class="st"> </span><span class="kw">recipe</span>(Class <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> okc) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># specify the variable being encoded and the outcome</span>
<span class="st">  </span><span class="kw"><a href="../../reference/step_lencode_glm.html">step_lencode_glm</a></span>(location, <span class="dt">outcome =</span> <span class="kw">vars</span>(Class)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># estimate the effects</span>
<span class="st">  </span><span class="kw">prep</span>(<span class="dt">training =</span> okc)</code></pre></div>
<p>The <code>tidy</code> method can be used to extract the encodings and are merged with the raw estimates:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">estimates &lt;-<span class="st"> </span><span class="kw">tidy</span>(okc_glm, <span class="dt">number =</span> <span class="dv">1</span>)
estimates</code></pre></div>
<pre><code>## # A tibble: 136 x 3
##    level              value terms   
##    &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;   
##  1 alameda            -1.79 location
##  2 albany             -1.64 location
##  3 arcadia           -14.6  location
##  4 ashland           -14.6  location
##  5 atherton           -1.25 location
##  6 bayshore          -14.6  location
##  7 belmont            -1.25 location
##  8 belvedere tiburon  -2.58 location
##  9 benicia            -2.39 location
## 10 berkeley           -1.82 location
## # ... with 126 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">estimates &lt;-<span class="st"> </span>estimates <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">select</a></span>(<span class="op">-</span>terms) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">set_names</span>(<span class="kw">c</span>(<span class="st">"location"</span>, <span class="st">"glm"</span>)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">inner_join</span>(props, <span class="dt">by =</span> <span class="st">"location"</span>)</code></pre></div>
<p>For the locations with <code>n &gt; 1</code>, the estimates are effectively the same:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">estimates <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/filter.html">filter</a></span>(<span class="kw">is.finite</span>(log_odds)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">difference =</span> log_odds<span class="op">-</span>glm) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">select</a></span>(difference) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summary</span>()</code></pre></div>
<pre><code>##    difference        
##  Min.   :-2.016e-13  
##  1st Qu.:-6.661e-15  
##  Median :-7.772e-16  
##  Mean   :-2.146e-16  
##  3rd Qu.: 6.661e-16  
##  Max.   : 3.666e-13</code></pre>
<p>Note that there is also a effect that is used for a novel location for future data sets that is the average effect:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tidy</span>(okc_glm, <span class="dt">number =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/filter.html">filter</a></span>(level <span class="op">==</span><span class="st"> "..new"</span>) </code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   level value terms   
##   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;   
## 1 ..new -7.79 location</code></pre>
</div>
<div id="partial-pooling" class="section level2">
<h2 class="hasAnchor">
<a href="#partial-pooling" class="anchor"></a>Partial Pooling</h2>
<p>This method estimates the effects by using all of the locations at once using a hierarchical Bayesian generalized linear model. The locations are treated as a random set that contributes a random intercept to the previously used logistic regression.</p>
<p>Partial pooling estimates each effect as a combination of the separate empirical estimates of the log-odds and the prior distribution. For locations with small sample sizes, the final estimate is <em>shrunken</em> towards the overall mean of the log-odds. This makes sense since we have poor information for estimating these locations. For locations with many data points, the estimates reply more on the empirical estimates. <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/glmer.html">This page</a> has a good discussion of pooling using Bayesian models.</p>
<div id="bayesian-methods" class="section level3">
<h3 class="hasAnchor">
<a href="#bayesian-methods" class="anchor"></a>Bayesian Methods</h3>
<p>One appraoch to partial pooling is the function <code>step_lencode_bayes</code> uses the <code>stan_glmer</code> function in the <code>rstanarm</code> package. There are a number of options that can be used to control the model estimation routine, including:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">opts &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">list</span>(
    ## the number of chains
    <span class="dt">chains =</span> <span class="dv">4</span>,
    ## how many cores to use 
    <span class="dt">cores =</span> <span class="dv">4</span>,
    ## the total number of iterations per chain (low here for time)
    <span class="dt">iter =</span> <span class="dv">500</span>,
    ## set the random number seed
    <span class="dt">seed =</span> <span class="dv">8779</span>
  )</code></pre></div>
<p>Using the default priors, the model is estimated via:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">okc_glmer &lt;-<span class="st"> </span><span class="kw">recipe</span>(Class <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> okc) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../../reference/step_lencode_bayes.html">step_lencode_bayes</a></span>(
    location,
    <span class="dt">outcome =</span> <span class="kw">vars</span>(Class),
    <span class="dt">options =</span> opts
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">prep</span>(<span class="dt">training =</span> okc)</code></pre></div>
<p>This took more time than the simple non-pooled model. The embeddings are extracted in the same way:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">estimates &lt;-<span class="st"> </span><span class="kw">tidy</span>(okc_glmer, <span class="dt">number =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">select</a></span>(<span class="op">-</span>terms) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">set_names</span>(<span class="kw">c</span>(<span class="st">"location"</span>, <span class="st">"glmer"</span>)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">inner_join</span>(estimates, <span class="dt">by =</span> <span class="st">"location"</span>)
estimates <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">select</a></span>(location, log_odds, glm, glmer)</code></pre></div>
<pre><code>## # A tibble: 135 x 4
##    location          log_odds    glm glmer
##    &lt;chr&gt;                &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
##  1 alameda              -1.79  -1.79 -1.80
##  2 albany               -1.64  -1.64 -1.69
##  3 arcadia            -Inf    -14.6  -2.00
##  4 ashland            -Inf    -14.6  -1.96
##  5 atherton             -1.25  -1.25 -1.51
##  6 bayshore           -Inf    -14.6  -2.04
##  7 belmont              -1.25  -1.25 -1.32
##  8 belvedere tiburon    -2.58  -2.58 -2.30
##  9 benicia              -2.39  -2.39 -2.31
## 10 berkeley             -1.82  -1.82 -1.82
## # ... with 125 more rows</code></pre>
<p>Note that the <code>n = 1</code> locations have estimates that are less extreme that the naive estimates. Also,</p>
<p>Let’s see the effect of the shrinkage indued by partial pooling by plotting the naive results versus the new results (finite data only):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">estimates <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/filter.html">filter</a></span>(<span class="kw">is.finite</span>(log_odds)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> log_odds, <span class="dt">y =</span> glmer)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">col =</span> <span class="st">"red"</span>, <span class="dt">alpha =</span> .<span class="dv">5</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">size =</span> <span class="kw">sqrt</span>(n)), <span class="dt">alpha =</span> .<span class="dv">5</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">xlim</span>(rng) <span class="op">+</span><span class="st"> </span><span class="kw">ylim</span>(rng) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="GLM_files/figure-html/stan-compare-1.png" width="700"></p>
<p>New levels are encoded as:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tidy</span>(okc_glmer, <span class="dt">number =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/filter.html">filter</a></span>(level <span class="op">==</span><span class="st"> "..new"</span>) </code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   level value terms   
##   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;   
## 1 ..new -1.98 location</code></pre>
</div>
<div id="empirical-bayesian-methodsmixed-models" class="section level3">
<h3 class="hasAnchor">
<a href="#empirical-bayesian-methodsmixed-models" class="anchor"></a>Empirical Bayesian Methods/Mixed Models</h3>
<p>The same generalized linear model can be fit using mixed models via a random intercept. The <code>lme4</code> package can also be used to get pooled estimates via <code>step_lencode_mixed</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">okc_mixed &lt;-<span class="st"> </span><span class="kw">recipe</span>(Class <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> okc) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../../reference/step_lencode_mixed.html">step_lencode_mixed</a></span>(
    location,
    <span class="dt">outcome =</span> <span class="kw">vars</span>(Class),
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">prep</span>(<span class="dt">training =</span> okc)

estimates &lt;-<span class="st"> </span><span class="kw">tidy</span>(okc_mixed, <span class="dt">number =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">select</a></span>(<span class="op">-</span>terms) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">set_names</span>(<span class="kw">c</span>(<span class="st">"location"</span>, <span class="st">"mixed"</span>)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">inner_join</span>(estimates, <span class="dt">by =</span> <span class="st">"location"</span>)
estimates <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">select</a></span>(location, log_odds, glm, glmer, mixed)</code></pre></div>
<pre><code>## # A tibble: 135 x 5
##    location          log_odds    glm glmer mixed
##    &lt;chr&gt;                &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1 alameda              -1.79  -1.79 -1.80 -1.80
##  2 albany               -1.64  -1.64 -1.69 -1.67
##  3 arcadia            -Inf    -14.6  -2.00 -1.97
##  4 ashland            -Inf    -14.6  -1.96 -1.97
##  5 atherton             -1.25  -1.25 -1.51 -1.50
##  6 bayshore           -Inf    -14.6  -2.04 -2.03
##  7 belmont              -1.25  -1.25 -1.32 -1.31
##  8 belvedere tiburon    -2.58  -2.58 -2.30 -2.27
##  9 benicia              -2.39  -2.39 -2.31 -2.30
## 10 berkeley             -1.82  -1.82 -1.82 -1.82
## # ... with 125 more rows</code></pre>
<p>Comparing the raw and mixed model estimates:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">estimates <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/filter.html">filter</a></span>(<span class="kw">is.finite</span>(log_odds)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> log_odds, <span class="dt">y =</span> mixed)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">col =</span> <span class="st">"red"</span>, <span class="dt">alpha =</span> .<span class="dv">5</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">size =</span> <span class="kw">sqrt</span>(n)), <span class="dt">alpha =</span> .<span class="dv">5</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">xlim</span>(rng) <span class="op">+</span><span class="st"> </span><span class="kw">ylim</span>(rng) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="GLM_files/figure-html/mixed-compare-1.png" width="700"></p>
<p>These values are very similar to the Bayesian estimates.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#no-pooling">No Pooling</a></li>
      <li><a href="#partial-pooling">Partial Pooling</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="tidyverse">
  <p>embed is a part of the <strong>tidyverse</strong>, an ecosystem of packages designed with common APIs and a shared philosophy. Learn more at <a href="https://tidyverse.org">tidyverse.org</a>.</p>
</div>

<div class="author">
  <p>Developed by Max Kuhn.</p>
  <p>Site built by <a href="https://pkgdown.r-lib.org">pkgdown</a>.</p>
</div>

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-115082821-1"></script><script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());

 gtag('config', 'UA-115082821-1');
</script></footer>
</div>

  

  </body>
</html>
